[supervisord]
nodaemon=true
environment=HADOOP_CONF_DIR="/etc/hadoop/conf:/etc/hbase/conf",HOSTNAME=%(ENV_HOSTNAME)s

[program:master]
stdout_logfile=/dev/fd/1
stdout_logfile_maxbytes=0
stderr_logfile=/dev/fd/2
stderr_logfile_maxbytes=0
startsecs=30
exitcodes=0,2
stopsignal=TERM
stopwaitsecs=60
autorestart=unexpected
startretries=999999999
environment=WASP_HOME=/code/master/
command=/code/master/bin/wasp-whitelabel-master
  -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5005
  -J-Xmx%(ENV_MASTER_MEMORY)s -J-Xms%(ENV_MASTER_MEMORY)s
  -Dlog4j.configurationFile=file:///log4j2.properties
  -Dconfig.file=/wasp.conf
  -Dwasp.process="---master"
  -Dwasp.akka.remote.netty.tcp.hostname=%(ENV_HOSTNAME)s
  -Dwasp.akka.remote.netty.tcp.port=2892
  -Dwasp.akka.cluster.seed-nodes.0="akka.tcp://WASP@%(ENV_HOSTNAME)s:2892"

[program:producers]
stdout_logfile=/dev/fd/1
stdout_logfile_maxbytes=0
stderr_logfile=/dev/fd/2
stderr_logfile_maxbytes=0
startsecs=30
exitcodes=0,2
stopsignal=TERM
stopwaitsecs=60
autorestart=unexpected
startretries=999999999
environment=WASP_HOME=/code/producer/
command=/code/producer/bin/wasp-whitelabel-producers
  -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5006
  -J-Xmx%(ENV_PRODUCERS_MEMORY)s -J-Xms%(ENV_PRODUCERS_MEMORY)s
  -Dlog4j.configurationFile=file:///log4j2.properties
  -Dconfig.file=/wasp.conf
  -Dwasp.process="producers"
  -Dwasp.akka.remote.netty.tcp.hostname=%(ENV_HOSTNAME)s
  -Dwasp.akka.remote.netty.tcp.port=2893
  -Dwasp.akka.cluster.seed-nodes.0="akka.tcp://WASP@%(ENV_HOSTNAME)s:2892"

[program:consumers-streaming]
stdout_logfile=/dev/fd/1
stdout_logfile_maxbytes=0
stderr_logfile=/dev/fd/2
stderr_logfile_maxbytes=0
startsecs=30
exitcodes=0,2
stopsignal=TERM
stopwaitsecs=60
autorestart=unexpected
startretries=999999999
environment=WASP_HOME=/code/consumers-spark/
command=/code/consumers-spark/bin/wasp-whitelabel-consumers-spark
  -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5007
  -J-Xmx%(ENV_SPARK_STREAMING_MEMORY)s -J-Xms%(ENV_SPARK_STREAMING_MEMORY)s
  -Dlog4j.configurationFile=file:///log4j2.properties
  -Dconfig.file=/wasp.conf
  -Dwasp.process="streaming"
  -Dwasp.akka.remote.netty.tcp.hostname=%(ENV_HOSTNAME)s
  -Dwasp.akka.remote.netty.tcp.port=2894
  -Dwasp.akka.cluster.roles.0="consumers-spark-streaming"
  -Dwasp.akka.cluster.seed-nodes.0="akka.tcp://WASP@%(ENV_HOSTNAME)s:2892"
  -main it.agilelab.bigdata.wasp.whitelabel.consumers.spark.launcher.SparkConsumersStreamingNodeLauncher

[program:consumers-batch]
stdout_logfile=/dev/fd/1
stdout_logfile_maxbytes=0
stderr_logfile=/dev/fd/2
stderr_logfile_maxbytes=0
startsecs=30
exitcodes=0,2
stopsignal=TERM
stopwaitsecs=60
autorestart=unexpected
startretries=999999999
environment=WASP_HOME=/code/consumers-spark/
command=/code/consumers-spark/bin/wasp-whitelabel-consumers-spark
  -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5008
  -J-Xmx%(ENV_SPARK_BATCH_MEMORY)s -J-Xms%(ENV_SPARK_BATCH_MEMORY)s
  -Dlog4j.configurationFile=file:///log4j2.properties
  -Dconfig.file=/wasp.conf
  -Dwasp.process="----batch"
  -Dwasp.akka.remote.netty.tcp.hostname=%(ENV_HOSTNAME)s
  -Dwasp.akka.remote.netty.tcp.port=2895
  -Dwasp.akka.cluster.roles.0="consumers-spark-batch"
  -Dwasp.akka.cluster.seed-nodes.0="akka.tcp://WASP@%(ENV_HOSTNAME)s:2892"
  -main it.agilelab.bigdata.wasp.whitelabel.consumers.spark.launcher.SparkConsumersBatchNodeLauncher





