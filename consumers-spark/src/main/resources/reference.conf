wasp {
  akka {
    cluster {
      # NOT WORK WITH SINGLETONS
      #roles = ["consumers-spark-streaming", "consumers-spark-batch"]
    }

    actor {

      serializers {
        kryo = "com.romix.akka.serialization.kryo.KryoSerializer"
      }

      kryo {
        # Possible values for idstrategy are:
        # default, explicit, incremental, automatic
        #
        # default - slowest and produces bigger serialized representation. Contains fully-
        # qualified class names (FQCNs) for each class
        #
        # explicit - fast and produces compact serialized representation. Requires that all
        # classes that will be serialized are pre-registered using the "mappings" and "classes"
        # sections. To guarantee that both sender and receiver use the same numeric ids for the same
        # classes it is advised to provide exactly the same entries in the "mappings" section
        #
        # incremental - fast and produces compact serialized representation. Support optional
        # pre-registering of classes using the "mappings" and "classes" sections. If class is
        # not pre-registered, it will be registered dynamically by picking a next available id
        # To guarantee that both sender and receiver use the same numeric ids for the same
        # classes it is advised to pre-register them using at least the "classes" section
        #
        # automatic - Contains fully-qualified class names (FQCNs) for each class that is not
        # pre-registered in the "mappings" and "classes" section

        idstrategy = "default"
      }
      serialization-bindings {
        "it.agilelab.bigdata.wasp.consumers.spark.streaming.actor.master.Protocol" = kryo
        "it.agilelab.bigdata.wasp.consumers.spark.streaming.actor.pipegraph.Protocol" = kryo
        "it.agilelab.bigdata.wasp.consumers.spark.streaming.actor.etl.Protocol" = kryo
        "it.agilelab.bigdata.wasp.models.Model" = kryo
        "it.agilelab.bigdata.wasp.consumers.spark.streaming.actor.master.Protocol$WorkAvailable" = kryo
        "it.agilelab.bigdata.wasp.consumers.spark.streaming.actor.master.Protocol$WorkFailed" = kryo
        "it.agilelab.bigdata.wasp.consumers.spark.streaming.actor.master.Protocol$Initialize$" = kryo
        "it.agilelab.bigdata.wasp.consumers.spark.streaming.actor.master.Protocol$WorkCompleted$" = kryo
        "it.agilelab.bigdata.wasp.consumers.spark.streaming.actor.master.Protocol$WorkGiven" = kryo
        "it.agilelab.bigdata.wasp.consumers.spark.streaming.actor.master.Protocol$WorkNotGiven" = kryo
        "it.agilelab.bigdata.wasp.consumers.spark.streaming.actor.etl.Protocol$ETLNotActivated" = kryo
        "it.agilelab.bigdata.wasp.consumers.spark.streaming.actor.etl.Protocol$StopETL" = kryo
        "it.agilelab.bigdata.wasp.consumers.spark.streaming.actor.etl.Protocol$CheckETL" = kryo
        "it.agilelab.bigdata.wasp.consumers.spark.streaming.actor.etl.Protocol$ETLMaterialized" = kryo
        "it.agilelab.bigdata.wasp.consumers.spark.streaming.actor.etl.Protocol$ETLActivated" = kryo
        "it.agilelab.bigdata.wasp.consumers.spark.streaming.actor.etl.Protocol$ETLCheckSucceeded" = kryo
        "it.agilelab.bigdata.wasp.consumers.spark.streaming.actor.etl.Protocol$ActivateETL" = kryo
        "it.agilelab.bigdata.wasp.consumers.spark.streaming.actor.etl.Protocol$ETLNotMaterialized" = kryo
        "it.agilelab.bigdata.wasp.consumers.spark.streaming.actor.etl.Protocol$ETLCheckFailed" = kryo
        "it.agilelab.bigdata.wasp.consumers.spark.streaming.actor.etl.Protocol$MaterializeETL" = kryo
        "it.agilelab.bigdata.wasp.consumers.spark.streaming.actor.etl.Protocol$ETLStopped" = kryo
      }

    }
    remote {
      netty.tcp {
        port = 0
        hostname = "localhost"
      }
    }
  }
}